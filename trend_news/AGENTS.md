# TrendRadar (trend_news) - AI Coding Assistant Guide

**Version**: 1.0  
**Last Updated**: February 15, 2026  
**Purpose**: Help AI assistants quickly understand and work with this Vietnamese news scraping and sentiment analysis system

---

## ğŸ¯ Project Overview

**TrendRadar** (branded as `trend_news` in TradingAgents integration) is a Vietnamese news scraping, aggregation, and sentiment analysis system. It collects news from 30+ Vietnamese sources, performs sentiment analysis, and provides APIs for querying news data with Vietnamese stock market focus.

### Key Features
- âœ… **30+ Vietnamese news sources**: VnExpress, CafeF, DÃ¢n TrÃ­, Money24h, etc.
- âœ… **Real-time news scraping**: Automated crawling with configurable intervals
- âœ… **Sentiment analysis**: Lexicon-based with learning system
- âœ… **FastAPI server**: RESTful API compatible with Alpha Vantage format
- âœ… **MCP Server**: FastMCP 2.0 integration for AI agents
- âœ… **SQLite database**: Efficient storage and querying
- âœ… **Multi-mode reporting**: Daily, Incremental, Current
- âœ… **Notification system**: Telegram, Email support
- âœ… **Docker support**: Easy deployment

### Integration with TradingAgents
This project serves as a **data vendor** for the parent TradingAgents project, specifically providing Vietnamese market news with sentiment scores for stock analysis.

---

## ğŸ“ Critical File Locations

### Core System Files
```
trend_news/
â”œâ”€â”€ server.py                     # â­ FastAPI server (port 8000)
â”‚                                 # Alpha Vantage-compatible API
â”‚
â”œâ”€â”€ main.py                       # News scraping orchestrator
â”‚                                 # Multi-mode operation (daily/incremental/current)
â”‚
â”œâ”€â”€ mcp_server/
â”‚   â”œâ”€â”€ server.py                # FastMCP 2.0 server for AI agents
â”‚   â”œâ”€â”€ tools/                   # MCP tool implementations
â”‚   â”‚   â”œâ”€â”€ data_query.py        # News querying tools
â”‚   â”‚   â”œâ”€â”€ analytics.py         # Analytics and statistics
â”‚   â”‚   â”œâ”€â”€ search_tools.py      # Search functionality
â”‚   â”‚   â”œâ”€â”€ config_mgmt.py       # Configuration management
â”‚   â”‚   â””â”€â”€ system.py            # System management
â”‚   â”œâ”€â”€ services/                # Business logic services
â”‚   â”‚   â”œâ”€â”€ cache_service.py     # Caching layer
â”‚   â”‚   â”œâ”€â”€ data_service.py      # Data access layer
â”‚   â”‚   â””â”€â”€ parser_service.py    # Data parsing
â”‚   â””â”€â”€ utils/                   # Utilities
â”‚       â”œâ”€â”€ date_parser.py       # Date parsing (Vietnamese format)
â”‚       â”œâ”€â”€ errors.py            # Error handling
â”‚       â””â”€â”€ validators.py        # Input validation
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ settings.py          # Configuration loader
â”‚   â”‚   â””â”€â”€ constants.py         # System constants
â”‚   â”‚
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ database.py          # â­ SQLite database manager
â”‚   â”‚   â”œâ”€â”€ sentiment_learning.py # â­ Sentiment learning system
â”‚   â”‚   â”œâ”€â”€ analyzer.py          # Text analysis
â”‚   â”‚   â”œâ”€â”€ data_fetcher.py      # Generic data fetching
â”‚   â”‚   â”œâ”€â”€ vietnam_fetcher.py   # Vietnamese sources scraper
â”‚   â”‚   â””â”€â”€ keyword_extractor.py # Keyword extraction
â”‚   â”‚
â”‚   â”œâ”€â”€ scrapers/                # â­ Source-specific scrapers
â”‚   â”‚   â”œâ”€â”€ base_scraper.py      # Base scraper class
â”‚   â”‚   â”œâ”€â”€ vnexpress_scraper.py # VnExpress.net
â”‚   â”‚   â”œâ”€â”€ cafef_scraper.py     # CafeF.vn
â”‚   â”‚   â”œâ”€â”€ dantri_scraper.py    # DÃ¢n TrÃ­
â”‚   â”‚   â”œâ”€â”€ money24h_scraper.py  # Money24h
â”‚   â”‚   â””â”€â”€ ... (30+ total)
â”‚   â”‚
â”‚   â”œâ”€â”€ processors/
â”‚   â”‚   â”œâ”€â”€ data_processor.py    # Data processing pipeline
â”‚   â”‚   â”œâ”€â”€ report_processor.py  # Report generation
â”‚   â”‚   â””â”€â”€ statistics.py        # Statistics calculation
â”‚   â”‚
â”‚   â”œâ”€â”€ renderers/
â”‚   â”‚   â”œâ”€â”€ html_renderer.py     # HTML report generation
â”‚   â”‚   â””â”€â”€ telegram_renderer.py # Telegram formatting
â”‚   â”‚
â”‚   â”œâ”€â”€ notifiers/
â”‚   â”‚   â”œâ”€â”€ telegram.py          # Telegram notifications
â”‚   â”‚   â””â”€â”€ email.py             # Email notifications
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ sentiment.py         # â­ Sentiment calculation
â”‚       â”œâ”€â”€ text_utils.py        # Text processing
â”‚       â”œâ”€â”€ time_utils.py        # Time handling
â”‚       â””â”€â”€ format_utils.py      # Formatting utilities
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.yaml              # â­ Main configuration file
â”‚   â””â”€â”€ frequency_words.txt      # Keywords for tracking
â”‚
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ trend_news.db            # â­ SQLite database (news storage)
â”‚   â””â”€â”€ YYYYå¹´MMæœˆDDæ—¥/          # Daily output folders
â”‚       â”œâ”€â”€ html/                # HTML reports
â”‚       â””â”€â”€ txt/                 # Text reports
â”‚
â””â”€â”€ docs/
    â”œâ”€â”€ IMPLEMENTATION_SUMMARY.md # Implementation details
    â””â”€â”€ SENTIMENT_LEARNING.md     # Sentiment system documentation
```

### Entry Points
- **server.py** - FastAPI server for API access (port 8000)
- **main.py** - News scraping and processing
- **mcp_server/server.py** - MCP server for AI agent integration
- **sentiment_dashboard.py** - Web dashboard for sentiment visualization

---

## ğŸ”„ System Architecture

### Data Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    NEWS SCRAPING LAYER                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  VnExpress   â”‚  â”‚    CafeF     â”‚  â”‚  DÃ¢n TrÃ­     â”‚     â”‚
â”‚  â”‚   Scraper    â”‚  â”‚   Scraper    â”‚  â”‚   Scraper    â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚         â”‚                  â”‚                  â”‚              â”‚
â”‚         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚              â”‚
â”‚         â””â”€â”€â”‚  Money24h + 27 More  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚            â”‚     Scrapers         â”‚                          â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                       â”‚                                      â”‚
â”‚              VietnamDataFetcher                             â”‚
â”‚                       â”‚                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 PROCESSING LAYER                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              DataProcessor                           â”‚  â”‚
â”‚  â”‚  - Clean and normalize text                          â”‚  â”‚
â”‚  â”‚  - Extract keywords                                  â”‚  â”‚
â”‚  â”‚  - Detect duplicates                                 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                       â”‚                                      â”‚
â”‚                       â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚         SentimentAnalyzer                            â”‚  â”‚
â”‚  â”‚  - Lexicon-based scoring                             â”‚  â”‚
â”‚  â”‚  - Context analysis                                  â”‚  â”‚
â”‚  â”‚  - Company/ticker detection                          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                       â”‚                                      â”‚
â”‚                       â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚      SentimentLearningManager                        â”‚  â”‚
â”‚  â”‚  - Learn from feedback                               â”‚  â”‚
â”‚  â”‚  - Update lexicon weights                            â”‚  â”‚
â”‚  â”‚  - Improve accuracy over time                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                       â”‚                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  STORAGE LAYER                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚           DatabaseManager (SQLite)                   â”‚  â”‚
â”‚  â”‚                                                       â”‚  â”‚
â”‚  â”‚  Tables:                                             â”‚  â”‚
â”‚  â”‚  - news_articles: Scraped news with metadata        â”‚  â”‚
â”‚  â”‚  - sentiment_feedback: Learning data                â”‚  â”‚
â”‚  â”‚  - keyword_stats: Trending keywords                 â”‚  â”‚
â”‚  â”‚                                                       â”‚  â”‚
â”‚  â”‚  File: output/trend_news.db                         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                       â”‚                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    API LAYER                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚   FastAPI Server â”‚         â”‚    MCP Server    â”‚         â”‚
â”‚  â”‚   (port 8000)    â”‚         â”‚  (FastMCP 2.0)   â”‚         â”‚
â”‚  â”‚                  â”‚         â”‚                  â”‚         â”‚
â”‚  â”‚  Endpoints:      â”‚         â”‚  Tools:          â”‚         â”‚
â”‚  â”‚  - /query        â”‚         â”‚  - get_latest_news â”‚       â”‚
â”‚  â”‚  - /api/v1/news  â”‚         â”‚  - search_news   â”‚         â”‚
â”‚  â”‚  - /api/v1/stats â”‚         â”‚  - get_statisticsâ”‚         â”‚
â”‚  â”‚  - /health       â”‚         â”‚  - query_sentimentâ”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚         â”‚                            â”‚                      â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚                    â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   CLIENTS    â”‚
              â”‚              â”‚
              â”‚ - TradingAgents â”‚
              â”‚ - AI Agents  â”‚
              â”‚ - Web Apps   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Three Operating Modes

**1. Daily Mode (Tá»•ng há»£p hÃ ng ngÃ y)**
- Collects ALL news from the day
- Generates comprehensive daily report
- Use case: End-of-day analysis

**2. Incremental Mode (TÄƒng dáº§n)**
- Only NEW articles since last run
- Real-time updates
- Use case: Continuous monitoring

**3. Current Mode (Hiá»‡n táº¡i)**
- Current trending topics
- Ranking-based view
- Use case: Quick market pulse check

---

## ğŸ”Œ API Integration

### FastAPI Server (server.py)

**Start Server:**
```bash
cd trend_news
python server.py
# Server runs on http://localhost:8000
```

**Endpoints:**

#### 1. Alpha Vantage Compatible Format
```bash
# Get news with sentiment
GET /query?function=NEWS_SENTIMENT&tickers=Vingroup&time_from=20260201T0000&time_to=20260215T0000&limit=50

# Response format (Alpha Vantage style)
{
  "items": "50",
  "sentiment_score_definition": "x <= -0.35: Bearish...",
  "feed": [
    {
      "title": "Vingroup cÃ´ng bá»‘...",
      "url": "https://...",
      "time_published": "20260210T143000",
      "summary": "...",
      "source": "vnexpress_kinhdoanh",
      "overall_sentiment_score": 0.45,
      "overall_sentiment_label": "Bullish",
      "topics": ["Vingroup", "Vinfast"]
    }
  ]
}
```

#### 2. Native API Format
```bash
# Get news (native format)
GET /api/v1/news?start_date=2026-02-01&end_date=2026-02-15&limit=50&sources=vnexpress,cafef

# Get statistics
GET /api/v1/stats?days=7

# Get sentiment trends
GET /api/v1/sentiment/trends?ticker=Vingroup&days=30

# Health check
GET /health
```

#### 3. Markdown Format (for LLM consumption)
```python
# Internal function used by TradingAgents
from tradingagents.dataflows.trend_news_api import get_trend_news

news_md = get_trend_news("VIC.VN", "2026-02-01", "2026-02-15")
# Returns formatted markdown string
```

### MCP Server (mcp_server/server.py)

**Tools Available for AI Agents:**

```python
# 1. Data Query Tools
get_latest_news(platforms=["vnexpress", "cafef"], limit=50)
get_news_by_date(date="2026-02-15", platforms=None)
get_news_by_keyword(keyword="Vingroup", days_back=7)

# 2. Analytics Tools
get_statistics(days=7)
get_sentiment_trends(company="Vingroup", days=30)
get_top_keywords(days=7, top_n=20)

# 3. Search Tools
search_news(query="Vinfast má»Ÿ rá»™ng", exact_match=False)
find_related_news(article_id=12345, similarity_threshold=0.8)

# 4. Config Management
get_active_sources()
update_scraper_config(source_id="vnexpress", enabled=True)

# 5. System Management
trigger_scrape(sources=["vnexpress"], force=True)
get_system_health()
```

---

## ğŸ‡»ğŸ‡³ Vietnamese Market Focus

### Ticker Mapping

The system maps Vietnamese stock tickers to company names for news matching:

```python
# Defined in tradingagents/dataflows/trend_news_api.py
VIETNAMESE_TICKER_MAP = {
    "VIC.VN": ["Vingroup", "Vinhomes"],
    "VNM.VN": ["Vinamilk"],
    "VCB.VN": ["Vietcombank", "BIDV"],  # Note: Smart matching
    "VHM.VN": ["Vinhomes"],
    "FPT.VN": ["FPT"],
    "HPG.VN": ["HÃ²a PhÃ¡t", "Hoa Phat"],
    "TCB.VN": ["Techcombank"],
    "MSN.VN": ["Masan"],
    "VHC.VN": ["VÄ©nh HoÃ n"],
    "VRE.VN": ["Vincom Retail"],
    "GAS.VN": ["PV Gas"],
    "SAB.VN": ["Sabeco"],
    "PLX.VN": ["Petrolimex"],
    "POW.VN": ["PetroVietnam Power"],
    "MWG.VN": ["Mobile World", "Tháº¿ Giá»›i Di Äá»™ng"],
}
```

### News Sources (30+ total)

**Major Business Sources:**
- **VnExpress Kinh Doanh** (vnexpress_kinhdoanh)
- **CafeF** (cafef_congty, cafef_chungkhoan, cafef_batdongsan)
- **DÃ¢n TrÃ­ Kinh Doanh** (dantri_kinhdoanh)
- **Money24h** (money24h)
- **VietnamFinance** (vietnamfinance, vietnamfinance_taichinh, vietnamfinance_nganhang, vietnamfinance_batdongsan) âœ¨ NEW
- **BÃ¡o Äáº§u TÆ°** (baodautu)
- **Viá»‡t Stock** (vietstock)
- **CafeF Báº¥t Äá»™ng Sáº£n** (cafef_batdongsan)

**General News Sources:**
- VnExpress (general news)
- Tuá»•i Tráº»
- Thanh NiÃªn
- Zing News
- And 20+ more...

### Sentiment Analysis

**Lexicon-Based System:**
```python
# Basic sentiment calculation
sentiment_score = (positive_words - negative_words) / total_words

# Score ranges:
# x <= -0.35: Bearish
# -0.35 < x <= -0.15: Somewhat-Bearish
# -0.15 < x < 0.15: Neutral
# 0.15 <= x < 0.35: Somewhat-Bullish
# x >= 0.35: Bullish
```

**Learning System:**
The system learns from feedback to improve accuracy:

```python
from src.core.sentiment_learning import SentimentLearningManager

learning_mgr = SentimentLearningManager(db_path)

# Provide feedback
learning_mgr.record_feedback(
    article_id=123,
    predicted_sentiment=0.45,
    actual_sentiment=0.60,  # Corrected by analyst
    feedback_type="correction"
)

# System automatically adjusts lexicon weights
```

---

## ğŸ›  Adding New Features

### Adding a New News Source Scraper

**Example: Adding VietnamFinance scraper (recently added Feb 15, 2026)**

1. **Create scraper file:**
```python
# src/scrapers/vietnamfinance_scraper.py
from .base_scraper import BaseScraper
from typing import List, Dict
from bs4 import BeautifulSoup

class VietnamFinanceScraper(BaseScraper):
    """Scraper for VietnamFinance.vn"""
    
    BASE_URL = "https://vietnamfinance.vn"
    
    def __init__(self):
        super().__init__(
            source_id="vietnamfinance",
            source_name="VietnamFinance"
        )
    
    def get_url(self) -> str:
        return self.BASE_URL
    
    def parse_articles(self, soup: BeautifulSoup) -> List[Dict]:
        """
        Parse articles from VietnamFinance.
        
        Returns:
            List of news items with keys:
            - title: str
            - url: str
            - mobileUrl: str (optional)
        """
        articles = []
        seen_urls = set()
        
        # CSS selectors for article titles
        selectors = ["h2 a", "h3 a", ".article-list a"]
        
        for selector in selectors:
            elements = soup.select(selector)
            for elem in elements:
                title = self._clean_title(elem.get_text())
                url = elem.get('href', '')
                
                if not title or len(title) < 10:
                    continue
                
                if not url.startswith('http'):
                    url = self._normalize_url(url, self.BASE_URL)
                
                if url and url not in seen_urls and '.html' in url:
                    seen_urls.add(url)
                    articles.append({
                        "title": title,
                        "url": url,
                        "mobileUrl": ""
                    })
        
        return articles[:50]
```

2. **Register in __init__.py:**
```python
# src/scrapers/__init__.py
from .vietnamfinance_scraper import (
    VietnamFinanceScraper,
    VietnamFinanceTaiChinhScraper,
    VietnamFinanceNganHangScraper,
    VietnamFinanceBatDongSanScraper,
)

VIETNAM_SCRAPERS = {
    # ... existing scrapers ...
    "vietnamfinance": VietnamFinanceScraper,
    "vietnamfinance-taichinh": VietnamFinanceTaiChinhScraper,
    "vietnamfinance-nganhang": VietnamFinanceNganHangScraper,
    "vietnamfinance-batdongsan": VietnamFinanceBatDongSanScraper,
}
```

3. **Test the scraper:**
```bash
# Test scraping
cd trend_news
python3 -c "
from src.scrapers.vietnamfinance_scraper import VietnamFinanceScraper
scraper = VietnamFinanceScraper()
result = scraper.fetch()
print(f'Fetched {len(result[\"items\"])} articles')
"
```

4. **Add to configuration (optional):**
```yaml
# config/config.yaml
platforms:
  - id: vietnamfinance
    name: VietnamFinance
    enabled: true
    priority: 8  # Higher = more important
```

### Adding New Sentiment Analysis Features

1. **Extend sentiment calculator:**
```python
# src/utils/sentiment.py

def get_sentiment_with_context(text: str, company: str) -> Dict:
    """
    Enhanced sentiment with company-specific context.
    """
    base_sentiment = get_sentiment(text)
    
    # Add company-specific adjustments
    if company.lower() in text.lower():
        # Adjust based on context
        context_boost = analyze_context(text, company)
        base_sentiment += context_boost
    
    return {
        "score": base_sentiment,
        "label": sentiment_to_label(base_sentiment),
        "confidence": calculate_confidence(text)
    }
```

2. **Update learning system:**
```python
# src/core/sentiment_learning.py

class SentimentLearningManager:
    def train_from_historical_data(self, feedback_data: List[Dict]):
        """
        Train model from historical feedback.
        """
        for feedback in feedback_data:
            self._update_weights(
                feedback['text'],
                feedback['predicted'],
                feedback['actual']
            )
```

### Adding New API Endpoints

1. **Add endpoint to server.py:**
```python
# server.py

@app.get("/api/v1/sentiment/company/{ticker}")
async def get_company_sentiment(
    ticker: str,
    days: int = 7
) -> Dict:
    """
    Get aggregated sentiment for a company.
    """
    # Get company names from ticker
    companies = VIETNAMESE_TICKER_MAP.get(ticker, [ticker])
    
    # Query news
    news_items = db_manager.get_news_by_companies(
        companies=companies,
        days_back=days
    )
    
    # Calculate aggregate sentiment
    avg_sentiment = calculate_aggregate_sentiment(news_items)
    
    return {
        "ticker": ticker,
        "sentiment_score": avg_sentiment,
        "article_count": len(news_items),
        "period_days": days
    }
```

2. **Add MCP tool:**
```python
# mcp_server/tools/analytics.py

@mcp.tool
async def analyze_company_sentiment(
    ticker: str,
    days: int = 7
) -> str:
    """
    Analyze sentiment for a specific company over time.
    """
    data = _get_tools()['analytics'].get_company_sentiment(ticker, days)
    return format_sentiment_report(data)
```

---

## ğŸ§ª Testing and Debugging

### Quick Tests

```bash
# 1. Test database connection
cd trend_news
python3 -c "from src.core.database import DatabaseManager; db = DatabaseManager('output/trend_news.db'); print(f'DB has {db.count_articles()} articles')"

# 2. Test server
python server.py &
sleep 2
curl -s "http://localhost:8000/health" | python3 -m json.tool

# 3. Test scraping
python3 -c "from src.core.vietnam_fetcher import VietnamDataFetcher; fetcher = VietnamDataFetcher(); print(f'Loaded {len(fetcher.scrapers)} scrapers')"

# 4. Test sentiment
python3 -c "from src.utils.sentiment import get_sentiment; print(get_sentiment('Vingroup cÃ´ng bá»‘ káº¿ hoáº¡ch tÄƒng trÆ°á»Ÿng máº¡nh'))"

# 5. Test MCP server
cd mcp_server
python server.py
```

### Integration Test

```bash
# Run comprehensive integration test
cd trend_news
./tests/integration_test.sh

# Or run specific test
python -m pytest tests/test_server.py -v
```

### Debug Mode

**Enable debug logging:**
```python
# In any script
import logging
logging.basicConfig(level=logging.DEBUG)
```

**Debug database queries:**
```python
from src.core.database import DatabaseManager

db = DatabaseManager('output/trend_news.db')
db.debug = True  # Prints all SQL queries
```

### Common Issues

**Issue**: `Error: Database is locked`
```bash
# Solution: Check for other processes using the database
lsof | grep trend_news.db
# Kill blocking processes
kill -9 <PID>
```

**Issue**: `ImportError: No module named 'beautifulsoup4'`
```bash
# Solution: Install scraping dependencies
pip install beautifulsoup4 lxml requests
```

**Issue**: `Server returns 404 for /query`
```bash
# Solution: Check server is running
ps aux | grep "python.*server.py"
# Restart if needed
cd trend_news && python server.py &
```

**Issue**: `No news found for ticker VIC.VN`
```bash
# Solution: Check ticker mapping
python3 -c "from tradingagents.dataflows.trend_news_api import VIETNAMESE_TICKER_MAP; print(VIETNAMESE_TICKER_MAP.get('VIC.VN'))"

# Verify database has data
python3 -c "from src.core.database import DatabaseManager; db = DatabaseManager('output/trend_news.db'); print(db.search_by_keyword('Vingroup', limit=5))"
```

**Issue**: `Scraper timeout errors`
```bash
# Solution: Increase timeout in config
# Edit config/config.yaml:
scraper_settings:
  timeout: 30  # seconds
  retry_count: 3
```

---

## ğŸ“Š Configuration

### Main Config File (config/config.yaml)

```yaml
# Report mode: daily | incremental | current
report_mode: daily

# Database settings
database:
  path: output/trend_news.db
  auto_vacuum: true

# Scraper settings
scraper_settings:
  timeout: 15
  user_agent: "Mozilla/5.0..."
  retry_count: 2
  delay_between_requests: 1  # seconds

# Platforms to scrape
platforms:
  - id: vnexpress_kinhdoanh
    name: VnExpress Kinh Doanh
    enabled: true
    priority: 10
    
  - id: cafef_chungkhoan
    name: CafeF Chá»©ng KhoÃ¡n
    enabled: true
    priority: 9

# Sentiment settings
sentiment:
  lexicon_path: config/sentiment_lexicon.txt
  learning_enabled: true
  min_confidence: 0.5

# API settings
api:
  host: 0.0.0.0
  port: 8000
  cors_enabled: true
  rate_limit: 100  # requests per minute

# Notification settings (optional)
telegram:
  enabled: false
  bot_token: ""
  chat_id: ""

email:
  enabled: false
  smtp_server: smtp.gmail.com
  smtp_port: 587
  from_email: ""
  to_email: ""
```

### Keywords File (config/frequency_words.txt)

```text
# Add keywords to track (one per line)
Vingroup
Vinamilk
Vietcombank
HÃ²a PhÃ¡t
FPT
# Stock market terms
cá»• phiáº¿u
chá»©ng khoÃ¡n
Ä‘áº§u tÆ°
tÄƒng trÆ°á»Ÿng
sÃ¡p nháº­p
```

---

## ğŸ”‘ Key Design Principles

### 1. **Modular Architecture**
- Each scraper is independent
- Easy to add/remove sources
- Clean separation of concerns

### 2. **Fail-Safe Design**
- Graceful degradation if scraper fails
- Continues with other sources
- Logs errors but doesn't crash

### 3. **Performance Optimized**
- Database indexing for fast queries
- Caching frequently accessed data
- Async scraping where possible

### 4. **Learning System**
- Improves accuracy over time
- Adapts to Vietnamese language nuances
- User feedback integration

### 5. **API Compatibility**
- Alpha Vantage format for easy integration
- Native format for advanced features
- Markdown format for LLM consumption

---

## ğŸš€ Quick Start for AI Assistants

When helping with this project:

1. **Check if server is running**: `curl http://localhost:8000/health`
2. **Verify database exists**: `ls -lh trend_news/output/trend_news.db`
3. **Test scraper**: Check `src/scrapers/` for source-specific code
4. **Review config**: `config/config.yaml` for all settings
5. **Check logs**: Look in `output/` directory for error logs

### Common Tasks

**"Add support for a new Vietnamese news source"**
â†’ Create scraper in `src/scrapers/`, register in `vietnam_fetcher.py`, add to config

**"Fix sentiment analysis for specific company"**
â†’ Check `src/utils/sentiment.py`, update lexicon, provide feedback data

**"Add new API endpoint"**
â†’ Modify `server.py`, add to MCP tools if needed

**"Improve scraping speed"**
â†’ Check `scraper_settings` in config, implement async scraping, add caching

**"Debug why no news for certain ticker"**
â†’ Check ticker mapping, verify database has data, test scraper directly

---

## ğŸ“š Additional Resources

### Related Files
- **README.md** - User documentation
- **docs/IMPLEMENTATION_SUMMARY.md** - Technical implementation details
- **docs/SENTIMENT_LEARNING.md** - Sentiment system documentation
- **requirements.txt** - Python dependencies

### External Dependencies
- **FastAPI** - Web framework
- **FastMCP 2.0** - MCP server framework
- **BeautifulSoup4** - HTML parsing
- **SQLite** - Database
- **Uvicorn** - ASGI server

### Integration Points
- **TradingAgents** - Parent project using this as data vendor
- **Alpha Vantage API** - Compatible format for easy integration
- **MCP Protocol** - AI agent communication

---

## ğŸ”„ Recent Changes (February 15, 2026)

### Integration with TradingAgents
- âœ… Created `tradingagents/dataflows/trend_news_api.py` integration
- âœ… Added Vietnamese ticker mapping (VIC.VN, VNM.VN, etc.)
- âœ… Implemented Alpha Vantage-compatible API format
- âœ… Added markdown formatting for LLM consumption
- âœ… Created sentiment score conversion

### New Features
- âœ… MCP Server with FastMCP 2.0
- âœ… Sentiment learning system
- âœ… Multi-mode reporting (daily/incremental/current)
- âœ… 30+ Vietnamese news sources
- âœ… Company-specific sentiment tracking
- âœ… **VietnamFinance scraper** - Added support for vietnamfinance.vn with 4 sections (homepage, tÃ i chÃ­nh, ngÃ¢n hÃ ng, báº¥t Ä‘á»™ng sáº£n)

### Configuration Changes
```python
# In TradingAgents default_config.py
config["data_vendors"]["news_data"] = "trend_news"
config["trend_news_api_url"] = "http://localhost:8000"
config["trend_news_sources"] = []  # All sources by default
```

---

## ğŸ’¡ Tips for AI Assistants

1. **Always check server status** before debugging API issues
2. **Test scrapers individually** before running full pipeline
3. **Use debug logging** to trace sentiment calculation issues
4. **Check database directly** when news queries return empty
5. **Verify ticker mapping** for Vietnamese stocks (VIC.VN format)
6. **Test with Vietnamese text** - encoding matters!
7. **Use MCP tools** for AI agent integration, not direct API calls
8. **Check config.yaml first** - most behavior is configurable
9. **Review scraper logs** in output/ directory for errors
10. **Use integration tests** to verify end-to-end functionality

---

## ğŸ¯ Project Goals

### Short-term
- âœ… Stable scraping from 30+ sources
- âœ… Accurate sentiment analysis
- âœ… Fast API response times (<100ms)
- âœ… Integration with TradingAgents

### Long-term
- ğŸ”„ Machine learning-based sentiment (beyond lexicon)
- ğŸ”„ Real-time streaming API
- ğŸ”„ Multi-language support (English translations)
- ğŸ”„ Advanced analytics dashboard
- ğŸ”„ Historical trend analysis

---

**Project**: TrendRadar (trend_news)  
**Parent**: TradingAgents  
**Repository**: phanngoc/agent-trading  
**Made by**: phanngoc  
**License**: MIT  
**Contact**: Check repository for issues and discussions

---

## ğŸ“ Quick Reference

### Start Server
```bash
cd trend_news && python server.py
```

### Query News via API
```bash
curl "http://localhost:8000/query?function=NEWS_SENTIMENT&tickers=Vingroup&limit=10"
```

### Run Scraper
```bash
cd trend_news && python main.py
```

### Check Database
```bash
sqlite3 output/trend_news.db "SELECT COUNT(*) FROM news_articles;"
```

### Test Integration
```bash
cd .. && python -c "from tradingagents.dataflows.trend_news_api import get_trend_news; print(get_trend_news('VIC.VN', '2026-02-01', '2026-02-15'))"
```

**End of Guide** âœ¨
