"""
Integration Test: Cognee Index ‚Üí Query Pipeline
================================================

M·ª•c ƒë√≠ch: Verify to√†n b·ªô lu·ªìng index + query c·ªßa Cognee:
  1. Index c√°c b√†i b√°o t√†i ch√≠nh ti·∫øng Vi·ªát v√†o knowledge graph
  2. Query b·∫±ng t√™n c√¥ng ty / s·ª± ki·ªán / ng√†nh
  3. X√°c nh·∫≠n k·∫øt qu·∫£ tr·∫£ v·ªÅ c√≥ li√™n quan ƒë·∫øn query

Cognee Search Types ƒë∆∞·ª£c test:
  - CHUNKS           : t√¨m text chunks g·∫ßn gi·ªëng query (semantic similarity)
  - GRAPH_COMPLETION : LLM traverse Kuzu graph, tr·∫£ v·ªÅ c√¢u tr·∫£ l·ªùi t·ªïng h·ª£p
  - SUMMARIES        : t√¨m summary nodes trong graph

Ch·∫°y test (t·ª´ th∆∞ m·ª•c trend_news/):
    pytest tests/test_cognee_query.py -v -s -m integration
    pytest tests/test_cognee_query.py -v -m integration   # kh√¥ng th·∫•y print

Y√™u c·∫ßu:
    - OPENAI_API_KEY ho·∫∑c GEMINI_API_KEY trong .env
    - pip install cognee fastembed pytest pytest-asyncio
"""

import asyncio
import os
import sys
import shutil
import tempfile
from pathlib import Path
from typing import List, Dict, Any

import pytest

# ---------------------------------------------------------------------------
# Path setup
# ---------------------------------------------------------------------------
_TREND_NEWS_DIR = Path(__file__).parent.parent
if str(_TREND_NEWS_DIR) not in sys.path:
    sys.path.insert(0, str(_TREND_NEWS_DIR))

# ---------------------------------------------------------------------------
# Test corpus ‚Äî 6 b√†i b√°o ƒëa d·∫°ng theo c√¥ng ty v√† s·ª± ki·ªán
# ---------------------------------------------------------------------------
ARTICLES = [
    {
        "id": "vic_1",
        "text": (
            "TIN T·ª®C T√ÄI CH√çNH: [vnexpress] 2026-02-28\n"
            "Ti√™u ƒë·ªÅ: VinGroup ƒë·∫ßu t∆∞ 1 t·ª∑ USD v√†o VinFast ƒë·ªÉ m·ªü r·ªông th·ªã tr∆∞·ªùng M·ªπ v√† ch√¢u √Çu\n"
            "C·∫£m x√∫c th·ªã tr∆∞·ªùng: Bullish (+0.85)\n"
            "Ngu·ªìn: https://vnexpress.net/vingroup-vinfast-invest\n"
        ),
        "keywords": ["VinGroup", "VinFast"],
    },
    {
        "id": "vic_2",
        "text": (
            "TIN T·ª®C T√ÄI CH√çNH: [cafef] 2026-02-28\n"
            "Ti√™u ƒë·ªÅ: C·ªï phi·∫øu VIC tƒÉng 5% sau th√¥ng b√°o VinGroup mua l·∫°i chu·ªói b√°n l·∫ª\n"
            "C·∫£m x√∫c th·ªã tr∆∞·ªùng: Bullish (+0.72)\n"
            "Ngu·ªìn: https://cafef.vn/co-phieu-vic-tang\n"
        ),
        "keywords": ["VIC", "VinGroup"],
    },
    {
        "id": "fpt_1",
        "text": (
            "TIN T·ª®C T√ÄI CH√çNH: [vietstock] 2026-02-28\n"
            "Ti√™u ƒë·ªÅ: FPT c√¥ng b·ªë l·ª£i nhu·∫≠n qu√Ω 4/2025 tƒÉng 32% so v·ªõi c√πng k·ª≥ nh·ªù m·∫£ng ph·∫ßn m·ªÅm xu·∫•t kh·∫©u\n"
            "C·∫£m x√∫c th·ªã tr∆∞·ªùng: Bullish (+0.91)\n"
            "Ngu·ªìn: https://vietstock.vn/fpt-q4-2025\n"
        ),
        "keywords": ["FPT"],
    },
    {
        "id": "vcb_1",
        "text": (
            "TIN T·ª®C T√ÄI CH√çNH: [tinnhanhchungkhoan] 2026-02-28\n"
            "Ti√™u ƒë·ªÅ: Vietcombank VCB h·∫° l√£i su·∫•t cho vay h·ªó tr·ª£ doanh nghi·ªáp v·ª´a v√† nh·ªè\n"
            "C·∫£m x√∫c th·ªã tr∆∞·ªùng: Bullish (+0.55)\n"
            "Ngu·ªìn: https://tinnhanhchungkhoan.vn/vcb-ha-lai-suat\n"
        ),
        "keywords": ["Vietcombank", "VCB"],
    },
    {
        "id": "hpg_1",
        "text": (
            "TIN T·ª®C T√ÄI CH√çNH: [ndh] 2026-02-27\n"
            "Ti√™u ƒë·ªÅ: H√≤a Ph√°t HPG d·ª± ki·∫øn xu·∫•t kh·∫©u 1 tri·ªáu t·∫•n th√©p trong nƒÉm 2026\n"
            "C·∫£m x√∫c th·ªã tr∆∞·ªùng: Bullish (+0.68)\n"
            "Ngu·ªìn: https://ndh.vn/hoa-phat-xuat-khau-thep\n"
        ),
        "keywords": ["H√≤a Ph√°t", "HPG", "th√©p"],
    },
    {
        "id": "vnm_bearish",
        "text": (
            "TIN T·ª®C T√ÄI CH√çNH: [cafef] 2026-02-27\n"
            "Ti√™u ƒë·ªÅ: Vinamilk VNM gi·∫£m doanh thu qu√Ω 1 do s·ª©c mua s·ªØa s·ª•t gi·∫£m t·∫°i th·ªã tr∆∞·ªùng n·ªôi ƒë·ªãa\n"
            "C·∫£m x√∫c th·ªã tr∆∞·ªùng: Bearish (-0.45)\n"
            "Ngu·ªìn: https://cafef.vn/vinamilk-vnm-giam-doanh-thu\n"
        ),
        "keywords": ["Vinamilk", "VNM"],
    },
]


# ---------------------------------------------------------------------------
# Fixtures
# ---------------------------------------------------------------------------


@pytest.fixture(scope="module")
def cognee_temp_dir():
    """Isolated temp directory for this test module."""
    tmp = tempfile.mkdtemp(prefix="test_cognee_query_")
    print(f"\n[fixture] Temp dir: {tmp}")
    yield tmp
    shutil.rmtree(tmp, ignore_errors=True)
    print(f"\n[fixture] Cleaned up: {tmp}")


@pytest.fixture(scope="module")
def cognee_paths(cognee_temp_dir):
    system_root = Path(cognee_temp_dir) / "cognee_system"
    return {
        "system_root": system_root,
        "databases_dir": system_root / "databases",
        "data_root": Path(cognee_temp_dir) / "data_storage",
    }


@pytest.fixture(scope="module")
def configured_cognee(cognee_paths):
    """Setup cognee v·ªõi temp dir + config. Yields cognee module."""
    from chatbot.config import COGNEE_LLM_CONFIG, COGNEE_EMBEDDING_ENV

    os.environ["SYSTEM_ROOT_DIRECTORY"] = str(cognee_paths["system_root"])
    os.environ["DATA_ROOT_DIRECTORY"] = str(cognee_paths["data_root"])
    for key, value in COGNEE_EMBEDDING_ENV.items():
        os.environ.setdefault(key, value)

    import cognee

    cognee.config.set_graph_database_provider("kuzu")
    cognee.config.set_llm_config(COGNEE_LLM_CONFIG)
    print(f"\n[cognee] LLM model: {COGNEE_LLM_CONFIG.get('llm_model')}")
    yield cognee


@pytest.fixture(scope="module")
async def indexed_cognee(configured_cognee):
    """
    Add t·∫•t c·∫£ ARTICLES v√†o cognee v√† ch·∫°y cognify() 1 l·∫ßn duy nh·∫•t.

    D√πng chung cho t·∫•t c·∫£ query tests trong module ‚Äî tr√°nh g·ªçi cognify()
    l·∫∑p l·∫°i nhi·ªÅu l·∫ßn (t·ªën token + th·ªùi gian).

    Tr·∫£ v·ªÅ cognee module ƒë√£ c√≥ data s·∫µn s√†ng ƒë·ªÉ search.
    """
    cog = configured_cognee

    print(f"\n[setup] Indexing {len(ARTICLES)} articles...")
    for i, article in enumerate(ARTICLES, 1):
        await asyncio.wait_for(cog.add(article["text"]), timeout=60)
        print(f"[setup]   [{i}/{len(ARTICLES)}] Added: {article['id']}")

    print("[setup] Running cognify()...")
    await asyncio.wait_for(cog.cognify(), timeout=300)
    print("[setup] cognify() done ‚úì")

    yield cog


# ---------------------------------------------------------------------------
# Helper
# ---------------------------------------------------------------------------


def _extract_text_from_results(results: Any) -> List[str]:
    """Flatten cognee search results th√†nh list of strings ƒë·ªÉ assert."""
    if not results:
        return []
    texts = []
    items = results if isinstance(results, list) else [results]
    for item in items:
        if isinstance(item, str):
            texts.append(item)
        elif hasattr(item, "text"):
            texts.append(str(item.text))
        elif isinstance(item, dict):
            texts.append(str(item.get("text", item)))
        else:
            texts.append(str(item))
    return [t for t in texts if t.strip()]


# ---------------------------------------------------------------------------
# Test 1: Sanity ‚Äî graph kh√¥ng r·ªóng
# ---------------------------------------------------------------------------


@pytest.mark.integration
@pytest.mark.asyncio
async def test_graph_not_empty_after_index(indexed_cognee):
    """
    Sau khi index 6 b√†i b√°o, graph ph·∫£i c√≥ √≠t nh·∫•t 1 node.

    N·∫øu is_empty() = True ‚Üí cognify() g·∫∑p l·ªói silent (LLM kh√¥ng extract
    ƒë∆∞·ª£c entity, ho·∫∑c API key sai).
    """
    from cognee.infrastructure.databases.graph import get_graph_engine

    graph_engine = await get_graph_engine()
    is_empty = await graph_engine.is_empty()

    assert not is_empty, (
        "Graph r·ªóng sau khi index 6 b√†i b√°o!\n"
        "‚Üí Ki·ªÉm tra LLM API key v√† model c√≥ ho·∫°t ƒë·ªông kh√¥ng"
    )
    print("\n[test] Graph kh√¥ng r·ªóng ‚úì")


# ---------------------------------------------------------------------------
# Test 2: CHUNKS search ‚Äî t√¨m theo t√™n c√¥ng ty
# ---------------------------------------------------------------------------


@pytest.mark.integration
@pytest.mark.asyncio
async def test_chunks_search_by_company_name(indexed_cognee):
    """
    CHUNKS search: query 'FPT' ph·∫£i tr·∫£ v·ªÅ √≠t nh·∫•t 1 k·∫øt qu·∫£.

    CHUNKS search = semantic similarity tr√™n text chunks ‚Äî nhanh, kh√¥ng c·∫ßn
    LLM inference th√™m. ƒê√¢y l√† c√°ch d√πng ph·ªï bi·∫øn nh·∫•t trong production.

    K·ª≥ v·ªçng: k·∫øt qu·∫£ ch·ª©a text li√™n quan ƒë·∫øn FPT (l·ª£i nhu·∫≠n, ph·∫ßn m·ªÅm...).
    """
    cog = indexed_cognee
    from cognee.api.v1.search.search import SearchType

    query = "FPT l·ª£i nhu·∫≠n"
    print(f"\n[test] CHUNKS search: '{query}'")

    results = await asyncio.wait_for(
        cog.search(query, SearchType.CHUNKS), timeout=60
    )

    texts = _extract_text_from_results(results)
    print(f"[test] Got {len(texts)} chunks:")
    for t in texts[:3]:
        print(f"  ‚Üí {t[:120]!r}")

    assert len(texts) > 0, (
        f"CHUNKS search '{query}' tr·∫£ v·ªÅ r·ªóng!\n"
        "‚Üí C√≥ th·ªÉ cognify() kh√¥ng t·∫°o ƒë∆∞·ª£c chunks ho·∫∑c embedding l·ªói"
    )


@pytest.mark.integration
@pytest.mark.asyncio
async def test_chunks_search_by_vingroup(indexed_cognee):
    """
    CHUNKS search: query 'VinGroup ƒë·∫ßu t∆∞' ph·∫£i tr·∫£ v·ªÅ k·∫øt qu·∫£ ch·ª©a VinGroup.

    Corpus c√≥ 2 b√†i v·ªÅ VinGroup/VIC ‚Üí k·∫øt qu·∫£ ph·∫£i ph·∫£n √°nh ƒëi·ªÅu n√†y.
    """
    cog = indexed_cognee
    from cognee.api.v1.search.search import SearchType

    query = "VinGroup ƒë·∫ßu t∆∞ m·ªü r·ªông"
    print(f"\n[test] CHUNKS search: '{query}'")

    results = await asyncio.wait_for(
        cog.search(query, SearchType.CHUNKS), timeout=60
    )

    texts = _extract_text_from_results(results)
    print(f"[test] Got {len(texts)} chunks:")
    for t in texts[:3]:
        print(f"  ‚Üí {t[:120]!r}")

    assert len(texts) > 0, f"CHUNKS search '{query}' tr·∫£ v·ªÅ r·ªóng!"

    # √çt nh·∫•t 1 k·∫øt qu·∫£ ƒë·ªÅ c·∫≠p VinGroup ho·∫∑c VinFast
    combined = " ".join(texts).lower()
    has_vingroup = any(kw.lower() in combined for kw in ["vingroup", "vinfast", "vic"])
    print(f"[test] VinGroup mentioned in results: {has_vingroup}")
    # Soft assert ‚Äî semantic search c√≥ th·ªÉ tr·∫£ v·ªÅ related content
    if not has_vingroup:
        print("  ‚ö†Ô∏è VinGroup kh√¥ng xu·∫•t hi·ªán tr·ª±c ti·∫øp ‚Äî k·∫øt qu·∫£ c√≥ th·ªÉ l√† semantic match")


@pytest.mark.integration
@pytest.mark.asyncio
async def test_chunks_search_bearish_news(indexed_cognee):
    """
    CHUNKS search: query tin t·ª©c ti√™u c·ª±c ph·∫£i t√¨m ƒë∆∞·ª£c b√†i Bearish.

    Corpus c√≥ 1 b√†i Bearish v·ªÅ Vinamilk. Query v·ªÅ 'gi·∫£m doanh thu'
    n√™n match v·ªõi b√†i ƒë√≥.
    """
    cog = indexed_cognee
    from cognee.api.v1.search.search import SearchType

    query = "gi·∫£m doanh thu s·ª•t gi·∫£m"
    print(f"\n[test] CHUNKS search: '{query}'")

    results = await asyncio.wait_for(
        cog.search(query, SearchType.CHUNKS), timeout=60
    )

    texts = _extract_text_from_results(results)
    print(f"[test] Got {len(texts)} chunks:")
    for t in texts[:3]:
        print(f"  ‚Üí {t[:120]!r}")

    assert len(texts) > 0, f"CHUNKS search '{query}' tr·∫£ v·ªÅ r·ªóng!"


# ---------------------------------------------------------------------------
# Test 3: GRAPH_COMPLETION search ‚Äî graph-based entity queries
# ---------------------------------------------------------------------------


@pytest.mark.integration
@pytest.mark.asyncio
async def test_insights_search_steel_sector(indexed_cognee):
    """
    GRAPH_COMPLETION search: query 'th√©p xu·∫•t kh·∫©u' ph·∫£i tr·∫£ v·ªÅ insights v·ªÅ H√≤a Ph√°t.

    GRAPH_COMPLETION d√πng Kuzu graph + LLM ƒë·ªÉ traverse relationships:
      Company(HPG) ‚Üí exports ‚Üí Steel ‚Üí to ‚Üí InternationalMarket

    K·∫øt qu·∫£ th∆∞·ªùng l√† c√¢u vƒÉn gi·∫£i th√≠ch m·ªëi quan h·ªá, kh√¥ng ph·∫£i raw chunks.
    """
    cog = indexed_cognee
    from cognee.api.v1.search.search import SearchType

    query = "th√©p xu·∫•t kh·∫©u"
    print(f"\n[test] GRAPH_COMPLETION search: '{query}'")

    results = await asyncio.wait_for(
        cog.search(query, SearchType.GRAPH_COMPLETION), timeout=90
    )

    texts = _extract_text_from_results(results)
    print(f"[test] Got {len(texts)} insights:")
    for t in texts[:3]:
        print(f"  ‚Üí {t[:200]!r}")

    assert len(texts) > 0, (
        f"GRAPH_COMPLETION search '{query}' tr·∫£ v·ªÅ r·ªóng!\n"
        "‚Üí Graph c√≥ th·ªÉ kh√¥ng extract ƒë∆∞·ª£c entity 'H√≤a Ph√°t' ho·∫∑c 'th√©p' t·ª´ text"
    )


@pytest.mark.integration
@pytest.mark.asyncio
async def test_insights_search_banking(indexed_cognee):
    """
    GRAPH_COMPLETION search: query 'ng√¢n h√†ng l√£i su·∫•t' ph·∫£i tr·∫£ v·ªÅ th√¥ng tin Vietcombank.

    Corpus c√≥ b√†i v·ªÅ VCB h·∫° l√£i su·∫•t ‚Üí graph n√™n c√≥:
      Entity(Vietcombank) ‚Üí action ‚Üí lower_interest_rate
    """
    cog = indexed_cognee
    from cognee.api.v1.search.search import SearchType

    query = "ng√¢n h√†ng l√£i su·∫•t cho vay"
    print(f"\n[test] GRAPH_COMPLETION search: '{query}'")

    results = await asyncio.wait_for(
        cog.search(query, SearchType.GRAPH_COMPLETION), timeout=90
    )

    texts = _extract_text_from_results(results)
    print(f"[test] Got {len(texts)} insights:")
    for t in texts[:3]:
        print(f"  ‚Üí {t[:200]!r}")

    assert len(texts) > 0, f"GRAPH_COMPLETION search '{query}' tr·∫£ v·ªÅ r·ªóng!"


# ---------------------------------------------------------------------------
# Test 4: parse_cognee_results utility
# ---------------------------------------------------------------------------


@pytest.mark.integration
@pytest.mark.asyncio
async def test_parse_cognee_results_chunks(indexed_cognee):
    """
    parse_cognee_results() ph·∫£i chuy·ªÉn ƒë·ªïi CHUNKS output th√†nh list[dict].

    Verify utility function t·ª´ chatbot/utils.py ho·∫°t ƒë·ªông v·ªõi raw cognee output,
    ƒë·∫£m b·∫£o chatbot c√≥ th·ªÉ hi·ªÉn th·ªã k·∫øt qu·∫£ cho user.

    Expected dict schema: {title, source_id, url, sentiment_label, sentiment_score}
    """
    cog = indexed_cognee
    from cognee.api.v1.search.search import SearchType
    from chatbot.utils import parse_cognee_results

    results = await asyncio.wait_for(
        cog.search("FPT ph·∫ßn m·ªÅm", SearchType.CHUNKS), timeout=60
    )

    parsed = parse_cognee_results(results)
    print(f"\n[test] parse_cognee_results: {len(parsed)} article(s)")
    for art in parsed[:3]:
        print(f"  title     : {art.get('title', '')[:80]!r}")
        print(f"  source_id : {art.get('source_id', '')!r}")
        print(f"  sentiment : {art.get('sentiment_label')} ({art.get('sentiment_score')})")

    # H√†m ph·∫£i tr·∫£ v·ªÅ list (c√≥ th·ªÉ r·ªóng n·∫øu format kh√¥ng match)
    assert isinstance(parsed, list), "parse_cognee_results ph·∫£i tr·∫£ v·ªÅ list"
    print("[test] parse_cognee_results tr·∫£ v·ªÅ list ‚úì")


@pytest.mark.integration
@pytest.mark.asyncio
async def test_parse_cognee_results_preserves_schema(indexed_cognee):
    """
    M·ªói article trong parse_cognee_results ph·∫£i c√≥ ƒë·ªß c√°c fields c·∫ßn thi·∫øt.

    Chatbot d√πng format_news_for_prompt() ƒë·ªÉ hi·ªÉn th·ªã ‚Üí c·∫ßn c√≥:
    title, source_id, url, sentiment_label, sentiment_score, crawled_at
    """
    cog = indexed_cognee
    from cognee.api.v1.search.search import SearchType
    from chatbot.utils import parse_cognee_results

    results = await asyncio.wait_for(
        cog.search("VinGroup VinFast th·ªã tr∆∞·ªùng M·ªπ", SearchType.CHUNKS), timeout=60
    )

    parsed = parse_cognee_results(results)

    required_keys = {"title", "source_id", "url", "sentiment_label", "sentiment_score"}
    for i, art in enumerate(parsed):
        missing = required_keys - set(art.keys())
        assert not missing, (
            f"Article [{i}] thi·∫øu fields: {missing}\n"
            f"Article content: {art}"
        )
    print(f"\n[test] All {len(parsed)} articles c√≥ ƒë·ªß required fields ‚úì")


# ---------------------------------------------------------------------------
# Test 5: Cross-company disambiguation
# ---------------------------------------------------------------------------


@pytest.mark.integration
@pytest.mark.asyncio
async def test_chunks_different_companies_return_different_results(indexed_cognee):
    """
    Query v·ªÅ 2 c√¥ng ty kh√°c nhau ph·∫£i tr·∫£ v·ªÅ k·∫øt qu·∫£ kh√°c nhau.

    Verify cognee kh√¥ng b·ªã "confused" v√† tr·∫£ v·ªÅ c√πng chunks cho m·ªçi query.
    So s√°nh top results c·ªßa FPT vs HPG ƒë·ªÉ ƒë·∫£m b·∫£o ch√∫ng differ.
    """
    cog = indexed_cognee
    from cognee.api.v1.search.search import SearchType

    results_fpt = await asyncio.wait_for(
        cog.search("FPT ph·∫ßn m·ªÅm xu·∫•t kh·∫©u", SearchType.CHUNKS), timeout=60
    )
    results_hpg = await asyncio.wait_for(
        cog.search("H√≤a Ph√°t th√©p s·∫£n xu·∫•t", SearchType.CHUNKS), timeout=60
    )

    texts_fpt = _extract_text_from_results(results_fpt)
    texts_hpg = _extract_text_from_results(results_hpg)

    print(f"\n[test] FPT query: {len(texts_fpt)} chunks")
    print(f"[test] HPG query: {len(texts_hpg)} chunks")

    assert len(texts_fpt) > 0, "FPT query tr·∫£ v·ªÅ r·ªóng!"
    assert len(texts_hpg) > 0, "HPG query tr·∫£ v·ªÅ r·ªóng!"

    # Top-1 c·ªßa 2 query ph·∫£i kh√°c nhau
    top_fpt = texts_fpt[0] if texts_fpt else ""
    top_hpg = texts_hpg[0] if texts_hpg else ""

    are_different = top_fpt != top_hpg
    print(f"[test] Top-1 results different: {are_different}")
    print(f"  FPT top-1 : {top_fpt[:80]!r}")
    print(f"  HPG top-1 : {top_hpg[:80]!r}")

    assert are_different, (
        "FPT v√† HPG queries tr·∫£ v·ªÅ c√πng top-1 result!\n"
        "‚Üí Cognee c√≥ th·ªÉ kh√¥ng ph√¢n bi·ªát ƒë∆∞·ª£c c√°c c√¥ng ty kh√°c nhau\n"
        "‚Üí Ki·ªÉm tra embedding model ho·∫°t ƒë·ªông ƒë√∫ng ch∆∞a"
    )


# ---------------------------------------------------------------------------
# Test 6: Print summary
# ---------------------------------------------------------------------------


@pytest.mark.integration
@pytest.mark.asyncio
async def test_print_query_summary(indexed_cognee, cognee_paths):
    """
    In ra summary to√†n b·ªô k·∫øt qu·∫£ ƒë·ªÉ developer review khi ch·∫°y pytest -s.

    Kh√¥ng c√≥ assertion ‚Äî d√πng ƒë·ªÉ debug v√† ki·ªÉm tra ch·∫•t l∆∞·ª£ng search.
    """
    cog = indexed_cognee
    from cognee.api.v1.search.search import SearchType

    test_queries = [
        ("FPT l·ª£i nhu·∫≠n tƒÉng tr∆∞·ªüng", SearchType.CHUNKS),
        ("VinGroup VinFast", SearchType.CHUNKS),
        ("ng√¢n h√†ng l√£i su·∫•t", SearchType.GRAPH_COMPLETION),
        ("H√≤a Ph√°t th√©p xu·∫•t kh·∫©u", SearchType.GRAPH_COMPLETION),
        ("Vinamilk gi·∫£m doanh thu", SearchType.CHUNKS),
    ]

    print("\n" + "=" * 70)
    print("COGNEE QUERY RESULTS SUMMARY")
    print("=" * 70)

    for query, search_type in test_queries:
        try:
            results = await asyncio.wait_for(
                cog.search(query, search_type), timeout=90
            )
            texts = _extract_text_from_results(results)
            print(f"\n‚ñ∂ [{search_type.name}] Query: {query!r}")
            print(f"  Returned {len(texts)} result(s)")
            for t in texts[:2]:
                print(f"  - {t[:100]!r}")
        except Exception as e:
            print(f"\n‚ñ∂ [{search_type.name}] Query: {query!r}")
            print(f"  ERROR: {e}")

    # Ki·ªÉm tra storage
    pkl_files = list(cognee_paths["databases_dir"].rglob("*.pkl")) if cognee_paths["databases_dir"].exists() else []
    print(f"\nüìÅ Storage: {len(pkl_files)} .pkl file(s) in databases/")
    for f in pkl_files:
        print(f"   - {f.name} ({f.stat().st_size / 1024:.1f} KB)")

    print("\n" + "=" * 70)
